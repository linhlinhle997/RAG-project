{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6693eff4289b4432ad54f137a6fe1fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ca25d1a885d40e28f0098f1a464dec6",
              "IPY_MODEL_31e77983fef54a9985e1ea5b8d09c820",
              "IPY_MODEL_a6859487b45d4941aa0a6a599723a7b4"
            ],
            "layout": "IPY_MODEL_965ed178c0884f91a0aeb1facbfa24e3"
          }
        },
        "4ca25d1a885d40e28f0098f1a464dec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03ad47b0542a4b1f8edc79dbb522a4db",
            "placeholder": "​",
            "style": "IPY_MODEL_2ed0628e8c154a269d60a0658e2dd0dd",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "31e77983fef54a9985e1ea5b8d09c820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36f5257f94244150a9ad873cc0c27b19",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7fba662167a4e1793deb79f562e890c",
            "value": 2
          }
        },
        "a6859487b45d4941aa0a6a599723a7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811d378b3142474c8d993dba5794bfd2",
            "placeholder": "​",
            "style": "IPY_MODEL_f9e71f27ce084a988ea56b2471b2e1b9",
            "value": " 2/2 [00:56&lt;00:00, 25.60s/it]"
          }
        },
        "965ed178c0884f91a0aeb1facbfa24e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ad47b0542a4b1f8edc79dbb522a4db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ed0628e8c154a269d60a0658e2dd0dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36f5257f94244150a9ad873cc0c27b19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7fba662167a4e1793deb79f562e890c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "811d378b3142474c8d993dba5794bfd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9e71f27ce084a988ea56b2471b2e1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6a1704ed47742649a9ee33eb26e38c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ffcfda9a3e2469aa5b6ffe4a73327c4",
              "IPY_MODEL_8868e525f6bf4bb9b6f32719e291bcac",
              "IPY_MODEL_3c535e9374b641cc8da74936ae440b30"
            ],
            "layout": "IPY_MODEL_c9249ea7802443fe99038471172910ee"
          }
        },
        "2ffcfda9a3e2469aa5b6ffe4a73327c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eedebfaa74674d80bb9b4f371d036eee",
            "placeholder": "​",
            "style": "IPY_MODEL_251171b819e940ada48445d0f8e6c1ba",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8868e525f6bf4bb9b6f32719e291bcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e77b0feedcb04800970600f4cd6f2f85",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f92b6602c20b447aaef73df42b45f897",
            "value": 2
          }
        },
        "3c535e9374b641cc8da74936ae440b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2e41ddf605a46209d57bc4d7ef5032d",
            "placeholder": "​",
            "style": "IPY_MODEL_fdef9edfbc394a17bb13234604fea4cb",
            "value": " 2/2 [00:57&lt;00:00, 26.04s/it]"
          }
        },
        "c9249ea7802443fe99038471172910ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eedebfaa74674d80bb9b4f371d036eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251171b819e940ada48445d0f8e6c1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e77b0feedcb04800970600f4cd6f2f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f92b6602c20b447aaef73df42b45f897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2e41ddf605a46209d57bc4d7ef5032d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdef9edfbc394a17bb13234604fea4cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linhlinhle997/RAG-project/blob/feature%2F01-rag-colab/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG-Project Code for Google Colab"
      ],
      "metadata": {
        "id": "x-Am0XV0_84f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setting Up the Environment\n",
        " Install necessary libraries to get started with the RAG project."
      ],
      "metadata": {
        "id": "Q69aE4cn-mEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljVFQbgZW647"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers==4.41.2\n",
        "!pip install -q bitsandbytes==0.43.1\n",
        "!pip install -q accelerate==0.31.0\n",
        "!pip install -q langchain==0.2.5\n",
        "!pip install -q langchainhub==0.1.20\n",
        "!pip install -q langchain-chroma==0.1.1\n",
        "!pip install -q langchain-community==0.2.5\n",
        "!pip install -q langchain_huggingface==0.0.3\n",
        "!pip install -q python-dotenv==1.0.1\n",
        "!pip install -q pypdf==4.2.0\n",
        "# !pip install -q numpy==1.24.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Building the Vector Database\n",
        "Create a vector database by processing and splitting a PDF document."
      ],
      "metadata": {
        "id": "8Qxwfc9t-yMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain import hub"
      ],
      "metadata": {
        "id": "zupsjIA6XIez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define paths and loader. Download file pdf from [here](https://drive.google.com/file/d/1rocVqBeUPsm2jXOgxq27DveuDI25HBHJ/view?usp=sharing)"
      ],
      "metadata": {
        "id": "rSFq1tXv_AAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Loader = PyPDFLoader\n",
        "FILE_PATH = \"/content/YOLOv10_Tutorials.pdf\"\n",
        "loader = Loader(FILE_PATH)"
      ],
      "metadata": {
        "id": "rmqQ_cxFYc5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load documents"
      ],
      "metadata": {
        "id": "RKEOlqa1_CN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "jF69CWKM-8QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split documents into smaller chunks"
      ],
      "metadata": {
        "id": "4BAJcT73_DpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "print(\"Number of sub-documents: \", len(docs))\n",
        "print(docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWRQqMfNaA4I",
        "outputId": "4a66dc42-0fe1-4ec8-e951-1a779f4ad39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sub-documents:  33\n",
            "page_content='AI VIET NAM – AI COURSE 2024\\nTutorial: Phát hiện đối tượng trong ảnh với\\nYOLOv10\\nDinh-Thang Duong, Nguyen-Thuan Duong, Minh-Duc Bui và\\nQuang-Vinh Dinh\\nNgày 20 tháng 6 năm 2024\\nI. Giới thiệu\\nObject Detection (Tạm dịch: Phát hiện đối tượng) là một bài toán cổ điển thuộc lĩnh vực\\nComputer Vision. Mục tiêu của bài toán này là tự động xác định vị trí của các đối tượng trong\\nmột tấm ảnh. Tính tới thời điểm hiện tại, đã có rất nhiều phương pháp được phát triển nhằm\\ngiải quyết hiệu quả bài toán này. Trong đó, các phương pháp thuộc họ YOLO (You Only Look\\nOnce) thu hút được sự chú ý rất lớn từ cộng đồng nghiên cứu bởi độ chính xác và tốc độ thực\\nthi mà loại mô hình này mang lại.\\nHình 1: Logo của mô hình YOLO. Ảnh: link.\\nThời gian vừa qua, Ao Wang và các cộng sự tại Đại học Thanh Hoa (Tsinghua University)\\nđã đề xuất mô hình YOLOv10 trong bài báo YOLOv10: Real-Time End-to-End Object\\nDetection [10]. Với những cải tiến mới, mô hình đã đạt được hiệu suất vượt trội hơn so với các' metadata={'source': '/content/YOLOv10_Tutorials.pdf', 'page': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize embeddings and vector database"
      ],
      "metadata": {
        "id": "V_fj5LHx_ORH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = HuggingFaceEmbeddings()\n",
        "vector_db = Chroma.from_documents(documents=docs, embedding=embedding)\n",
        "retriever = vector_db.as_retriever()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUDugdYSaKGJ",
        "outputId": "7c690652-7993-490c-d35f-0744eb5a31f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the retriever"
      ],
      "metadata": {
        "id": "FwXM20Zi_Qvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = retriever.invoke(\"What is YOLO?\")\n",
        "print(\"Number of relevant documents: \", len(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbCQzfUsavCE",
        "outputId": "725054c3-df34-4ba0-89c9-5f4c5fcd2020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of relevant documents:  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.  Initializing the Large Language Model\n",
        "Set up the Vicuna language model for processing queries."
      ],
      "metadata": {
        "id": "YE35745I_Sdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuration for the Vicuna model"
      ],
      "metadata": {
        "id": "hk_P6fCm_WjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nf4_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "RJbqLdFDa3c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model and tokenizer"
      ],
      "metadata": {
        "id": "qOfg9dku_hZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"lmsys/vicuna-7b-v1.5\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=nf4_config,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "6693eff4289b4432ad54f137a6fe1fcf",
            "4ca25d1a885d40e28f0098f1a464dec6",
            "31e77983fef54a9985e1ea5b8d09c820",
            "a6859487b45d4941aa0a6a599723a7b4",
            "965ed178c0884f91a0aeb1facbfa24e3",
            "03ad47b0542a4b1f8edc79dbb522a4db",
            "2ed0628e8c154a269d60a0658e2dd0dd",
            "36f5257f94244150a9ad873cc0c27b19",
            "a7fba662167a4e1793deb79f562e890c",
            "811d378b3142474c8d993dba5794bfd2",
            "f9e71f27ce084a988ea56b2471b2e1b9"
          ]
        },
        "id": "SheF1lfzbw4k",
        "outputId": "978e2982-cc3b-49d5-e1fb-cf432e478ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6693eff4289b4432ad54f137a6fe1fcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a pipeline for the model"
      ],
      "metadata": {
        "id": "DYo9znjz_mUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(\n",
        "    pipeline=model_pipeline\n",
        ")"
      ],
      "metadata": {
        "id": "tCR8st8rcRmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Running the RAG Program"
      ],
      "metadata": {
        "id": "LQ9yzPuZ_oha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# Format documents for the RAG chain\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Create the RAG chain\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Test the RAG system\n",
        "USER_QUESTION = \"YOLOv10 là gì?\"\n",
        "output = rag_chain.invoke(USER_QUESTION)\n",
        "answer = output.split(\"Answer: \")[1].strip()\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "4QkSnUCycpi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c59e46-6031-457e-b0fc-d9cbb57ad88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv10 là một phiên bản của YOLO (You Only Look Once) - một hệ thống dự đoán hình ảnh được huấn luyện sẵn trên bộ dữ liệu COCO. Phiên bản này được tạo bằng cách tải về trọng số (file.pt) từ GitHub và khởi tạo mô hình bằng cách sử dụng thư viện ultralytics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: Building a Chat Interface\n",
        "Create a chat interface for the RAG system using Chainlit."
      ],
      "metadata": {
        "id": "k3Hu2BNPAPk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers==4.41.2\n",
        "!pip install -q bitsandbytes==0.43.1\n",
        "!pip install -q accelerate==0.31.0\n",
        "!pip install -q langchain==0.2.5\n",
        "!pip install -q langchainhub==0.1.20\n",
        "!pip install -q langchain-chroma==0.1.1\n",
        "!pip install -q langchain-community==0.2.5\n",
        "!pip install -q langchain-openai==0.1.9\n",
        "!pip install -q langchain_huggingface==0.0.3\n",
        "!pip install -q chainlit==1.1.304\n",
        "!pip install -q python-dotenv==1.0.1\n",
        "!pip install -q pypdf==4.2.0\n",
        "!npm install -g localtunnel\n",
        "#pip install -q numpy==1.24.4"
      ],
      "metadata": {
        "id": "6T-1AapKhwCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58fca4d9-7c7c-4f78-c1b8-799b541bb842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package in 2.231s\n",
            "\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[33m   ╭────────────────────────────────────────────────────────────────╮\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                                \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m      New \u001b[31mmajor\u001b[39m version of npm available! \u001b[31m6.14.8\u001b[39m → \u001b[32m10.8.1\u001b[39m       \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m   \u001b[33mChangelog:\u001b[39m \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.8.1\u001b[39m   \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m               Run \u001b[32mnpm install -g npm\u001b[39m to update!                \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                                \u001b[33m│\u001b[39m\n",
            "\u001b[33m   ╰────────────────────────────────────────────────────────────────╯\u001b[39m\n",
            "\u001b[33m\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chainlit as cl\n",
        "import torch\n",
        "\n",
        "from chainlit.types import AskFileResponse\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain import hub"
      ],
      "metadata": {
        "id": "NR6BSTX7jmVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_split = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "embedding = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "xKZ9iSHTlS_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0ef4a2-e5ff-4052-d5cb-c9d4ddcb676e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file(file: AskFileResponse):\n",
        "    if file.type == \"text/plain\":\n",
        "        Loader = TextLoader\n",
        "    elif file.type == \"application/pdf\":\n",
        "        Loader = PyPDFLoader\n",
        "\n",
        "    loader = Loader(file.path)\n",
        "    documents = loader.load()\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "    for i, doc in enumerate(docs):\n",
        "        doc.metadata[\"source\"] = f\"source_{i}\"\n",
        "    return docs"
      ],
      "metadata": {
        "id": "IwlA-BIWldDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector_db(file:AskFileResponse):\n",
        "    docs = process_file(file)\n",
        "    cl.user_session.set(\"docs\", docs)\n",
        "    vector_db = Chroma.from_documents(documents=docs, embedding=embedding)\n",
        "    return vector_db"
      ],
      "metadata": {
        "id": "2tGKFRbol_QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_huggingface_llm(model_name: str = \"lmsys/vicuna-7b-v1.5\", max_new_token: int = 512):\n",
        "    nf4_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=nf4_config,\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    model_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=max_new_token,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    llm = HuggingFacePipeline(pipeline=model_pipeline)\n",
        "\n",
        "    return llm\n",
        "\n",
        "LLM = get_huggingface_llm()"
      ],
      "metadata": {
        "id": "wvwOUI1GmPtX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "f6a1704ed47742649a9ee33eb26e38c4",
            "2ffcfda9a3e2469aa5b6ffe4a73327c4",
            "8868e525f6bf4bb9b6f32719e291bcac",
            "3c535e9374b641cc8da74936ae440b30",
            "c9249ea7802443fe99038471172910ee",
            "eedebfaa74674d80bb9b4f371d036eee",
            "251171b819e940ada48445d0f8e6c1ba",
            "e77b0feedcb04800970600f4cd6f2f85",
            "f92b6602c20b447aaef73df42b45f897",
            "b2e41ddf605a46209d57bc4d7ef5032d",
            "fdef9edfbc394a17bb13234604fea4cb"
          ]
        },
        "outputId": "84c6efd6-c6f5-4fe2-f788-39a49cb0782f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6a1704ed47742649a9ee33eb26e38c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "welcome_message = \"\"\"\n",
        "    Welcome to the PDF QA! To get started:\n",
        "    1. Upload a PDF a text file\n",
        "    2. Ask a question about the file\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YPoxpASAqqtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@cl.on_chat_start\n",
        "async def on_chat_start():\n",
        "    files = None\n",
        "    while files is None:\n",
        "        files = await cl.AskFileMessage(\n",
        "            content=welcome_message,\n",
        "            accept=[\"text/plain\", \"application/pdf\"],\n",
        "            max_sixe_mb=20,\n",
        "            timeout=180\n",
        "        ).send()\n",
        "    file = files[0]\n",
        "\n",
        "    msg = cl.Message(content=f\"Processing '{file.name}'...\",\n",
        "                     disable_feedback=True)\n",
        "\n",
        "    await msg.send()\n",
        "\n",
        "    vector_db = await cl.make_async(get_vector_db)(file)\n",
        "\n",
        "    message_history = ChatMessageHistory()\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key=\"chat_history\",\n",
        "        output_key=\"answer\",\n",
        "        chat_memory=message_history,\n",
        "        return_messages=True\n",
        "    )\n",
        "    retriever = vector_db.as_retriever(search_type=\"mmr\",\n",
        "                                       search_kwargs={'k': 3})\n",
        "\n",
        "    chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=LLM,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        memory=memory,\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "    msg.content = f\"'{file.name}' process. You can now ask questions!\"\n",
        "    await msg.update()\n",
        "    cl.user_session.set(\"chain\", chain)"
      ],
      "metadata": {
        "id": "o-bUlRvprIk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@cl.on_message\n",
        "async def on_message(message: cl.Message):\n",
        "    chain = cl.user_session.get(\"chain\")\n",
        "    cb = cl.AsyncLangchainCallbackHandler()\n",
        "    res = await chain.ainvoke(message.content, callbacks=[cb])\n",
        "    answer = res[\"answer\"]\n",
        "    source_documents = res[\"source_documents\"]\n",
        "    text_elements = []\n",
        "\n",
        "    if source_documents:\n",
        "        for source_idx, source_doc in enumerate(source_documents):\n",
        "            source_name = f\"source_{source_idx}\"\n",
        "            text_elements.append(\n",
        "                cl.Text(content=source_doc.page_content, name=source_name)\n",
        "            )\n",
        "        source_names = [text_el.name for text_el in text_elements]\n",
        "\n",
        "        if source_names:\n",
        "            answer += f\"\\nSources: {', '.join(source_names)}\"\n",
        "        else:\n",
        "            answer += \"\\nNo sources found\"\n",
        "    await cl.Message(content=answer, elements=text_elements).send()"
      ],
      "metadata": {
        "id": "Y_s8uuKssZOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chainlit run app.py --host 0.0.0.0 --port 8000 &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "AuRPoDYutivG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib"
      ],
      "metadata": {
        "id": "DfU_XmxFtu-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Password/Endpoint IP for localtunnel is: \", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip('\\n'))"
      ],
      "metadata": {
        "id": "OAEVlqpMtxgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423b119f-41ac-41e4-b185-5b1467567a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Endpoint IP for localtunnel is:  34.142.223.183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lt --port 8000 --subdomain aivn-simple-rag"
      ],
      "metadata": {
        "id": "udNt4QGct_e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c4e58f0-55bb-4289-83c6-c9ffe0d5536b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://aivn-simple-rag.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}